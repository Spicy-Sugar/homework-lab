{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import packages\n",
    "import os\n",
    "import sys\n",
    "import operator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "from sklearn import model_selection, preprocessing, ensemble\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected object or value",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-db8ed190c2cd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#upload train data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./input/train.json\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"This is train data:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\suyun\\Anaconda3\\lib\\site-packages\\pandas\\io\\json\\json.py\u001b[0m in \u001b[0;36mread_json\u001b[1;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, lines)\u001b[0m\n\u001b[0;32m    352\u001b[0m         obj = FrameParser(json, orient, dtype, convert_axes, convert_dates,\n\u001b[0;32m    353\u001b[0m                           \u001b[0mkeep_default_dates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprecise_float\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 354\u001b[1;33m                           date_unit).parse()\n\u001b[0m\u001b[0;32m    355\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'series'\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\suyun\\Anaconda3\\lib\\site-packages\\pandas\\io\\json\\json.py\u001b[0m in \u001b[0;36mparse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    420\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    421\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 422\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parse_no_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    423\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\suyun\\Anaconda3\\lib\\site-packages\\pandas\\io\\json\\json.py\u001b[0m in \u001b[0;36m_parse_no_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    637\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0morient\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"columns\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    638\u001b[0m             self.obj = DataFrame(\n\u001b[1;32m--> 639\u001b[1;33m                 loads(json, precise_float=self.precise_float), dtype=None)\n\u001b[0m\u001b[0;32m    640\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0morient\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"split\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m             decoded = dict((str(k), v)\n",
      "\u001b[1;31mValueError\u001b[0m: Expected object or value"
     ]
    }
   ],
   "source": [
    "#upload train data\n",
    "train_df = pd.read_json(\"./input/train.json\")\n",
    "print(\"This is train data:\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No null values in the train data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "bathrooms          0\n",
       "bedrooms           0\n",
       "building_id        0\n",
       "created            0\n",
       "description        0\n",
       "display_address    0\n",
       "features           0\n",
       "interest_level     0\n",
       "latitude           0\n",
       "listing_id         0\n",
       "longitude          0\n",
       "manager_id         0\n",
       "photos             0\n",
       "price              0\n",
       "street_address     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to find if there's null value in the dataset\n",
    "print(\"No null values in the train data\")\n",
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data cleaning\n",
    "#basic features\n",
    "train_df[\"price_t\"] =train_df[\"price\"]/train_df[\"bedrooms\"]\n",
    "\n",
    "train_df[\"room_sum\"] = train_df[\"bedrooms\"]+train_df[\"bathrooms\"] \n",
    "\n",
    "# count of photos #\n",
    "train_df[\"num_photos\"] = train_df[\"photos\"].apply(len)\n",
    "\n",
    "# count of \"features\" #\n",
    "train_df[\"num_features\"] = train_df[\"features\"].apply(len)\n",
    "\n",
    "# count of words present in description column #\n",
    "train_df[\"num_description_words\"] = train_df[\"description\"].apply(lambda x: len(x.split(\" \")))\n",
    "\n",
    "#split the time data into year, month, day and hour\n",
    "train_df[\"created\"] = pd.to_datetime(train_df[\"created\"])\n",
    "\n",
    "train_df[\"created_year\"] = train_df[\"created\"].dt.year\n",
    "\n",
    "train_df[\"created_month\"] = train_df[\"created\"].dt.month\n",
    "\n",
    "train_df[\"created_day\"] = train_df[\"created\"].dt.day\n",
    "\n",
    "train_df[\"created_hour\"] = train_df[\"created\"].dt.hour\n",
    "\n",
    "features_to_use  = [\"bathrooms\", \"bedrooms\", \"latitude\", \"longitude\", \"price\"]\n",
    "features_to_use.extend([\"num_photos\", \"num_features\", \"num_description_words\",\n",
    "                        \"created_year\", \"created_month\", \"created_day\", \"listing_id\", \"created_hour\"])\n",
    "\n",
    "#deal with the address data and id data\n",
    "categorical = [\"display_address\", \"manager_id\", \"building_id\", \"street_address\"]\n",
    "for f in categorical:\n",
    "        if train_df[f].dtype=='object':\n",
    "            #print(f)\n",
    "            lbl = preprocessing.LabelEncoder()#Encode labels with value between 0 and n_classes-1.\n",
    "            lbl.fit(list(train_df[f].values))\n",
    "            train_df[f] = lbl.transform(list(train_df[f].values))\n",
    "            features_to_use.append(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>price</th>\n",
       "      <th>num_photos</th>\n",
       "      <th>num_features</th>\n",
       "      <th>num_description_words</th>\n",
       "      <th>created_year</th>\n",
       "      <th>created_month</th>\n",
       "      <th>created_day</th>\n",
       "      <th>listing_id</th>\n",
       "      <th>created_hour</th>\n",
       "      <th>display_address</th>\n",
       "      <th>manager_id</th>\n",
       "      <th>building_id</th>\n",
       "      <th>street_address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.5</td>\n",
       "      <td>3</td>\n",
       "      <td>40.7145</td>\n",
       "      <td>-73.9425</td>\n",
       "      <td>3000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>2016</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>7211212</td>\n",
       "      <td>7</td>\n",
       "      <td>6544</td>\n",
       "      <td>1239</td>\n",
       "      <td>2431</td>\n",
       "      <td>14074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>40.7947</td>\n",
       "      <td>-73.9667</td>\n",
       "      <td>5465</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>2016</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>7150865</td>\n",
       "      <td>12</td>\n",
       "      <td>4506</td>\n",
       "      <td>1583</td>\n",
       "      <td>5862</td>\n",
       "      <td>14195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100004</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>40.7388</td>\n",
       "      <td>-74.0018</td>\n",
       "      <td>2850</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>94</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>6887163</td>\n",
       "      <td>3</td>\n",
       "      <td>7387</td>\n",
       "      <td>2965</td>\n",
       "      <td>5806</td>\n",
       "      <td>5876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100007</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>40.7539</td>\n",
       "      <td>-73.9677</td>\n",
       "      <td>3275</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>6888711</td>\n",
       "      <td>2</td>\n",
       "      <td>5703</td>\n",
       "      <td>225</td>\n",
       "      <td>1201</td>\n",
       "      <td>8574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100013</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>40.8241</td>\n",
       "      <td>-73.9493</td>\n",
       "      <td>3350</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>6934781</td>\n",
       "      <td>1</td>\n",
       "      <td>8271</td>\n",
       "      <td>2081</td>\n",
       "      <td>0</td>\n",
       "      <td>11554</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        bathrooms  bedrooms  latitude  longitude  price  num_photos  \\\n",
       "10            1.5         3   40.7145   -73.9425   3000           5   \n",
       "10000         1.0         2   40.7947   -73.9667   5465          11   \n",
       "100004        1.0         1   40.7388   -74.0018   2850           8   \n",
       "100007        1.0         1   40.7539   -73.9677   3275           3   \n",
       "100013        1.0         4   40.8241   -73.9493   3350           3   \n",
       "\n",
       "        num_features  num_description_words  created_year  created_month  \\\n",
       "10                 0                     95          2016              6   \n",
       "10000              5                      9          2016              6   \n",
       "100004             4                     94          2016              4   \n",
       "100007             2                     80          2016              4   \n",
       "100013             1                     68          2016              4   \n",
       "\n",
       "        created_day  listing_id  created_hour  display_address  manager_id  \\\n",
       "10               24     7211212             7             6544        1239   \n",
       "10000            12     7150865            12             4506        1583   \n",
       "100004           17     6887163             3             7387        2965   \n",
       "100007           18     6888711             2             5703         225   \n",
       "100013           28     6934781             1             8271        2081   \n",
       "\n",
       "        building_id  street_address  \n",
       "10             2431           14074  \n",
       "10000          5862           14195  \n",
       "100004         5806            5876  \n",
       "100007         1201            8574  \n",
       "100013            0           11554  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Define X and y\n",
    "X = train_df[features_to_use]\n",
    "y = train_df[\"interest_level\"]\n",
    "X.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#split train data into two parts\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=123,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are all the coefficient of all features\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.080428e-08</td>\n",
       "      <td>3.430188e-07</td>\n",
       "      <td>6.303506e-08</td>\n",
       "      <td>-1.156729e-07</td>\n",
       "      <td>-0.000554</td>\n",
       "      <td>3.295821e-07</td>\n",
       "      <td>2.406693e-07</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.520470e-08</td>\n",
       "      <td>-1.238690e-06</td>\n",
       "      <td>-4.781419e-08</td>\n",
       "      <td>2.435864e-06</td>\n",
       "      <td>-0.000119</td>\n",
       "      <td>-0.000057</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.050641e-08</td>\n",
       "      <td>-4.155728e-07</td>\n",
       "      <td>-7.710697e-08</td>\n",
       "      <td>1.441497e-07</td>\n",
       "      <td>0.000355</td>\n",
       "      <td>-4.825485e-07</td>\n",
       "      <td>-1.067780e-06</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>1.164875e-08</td>\n",
       "      <td>7.607464e-07</td>\n",
       "      <td>-4.410861e-08</td>\n",
       "      <td>-1.781377e-06</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>-0.000136</td>\n",
       "      <td>-0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.193171e-09</td>\n",
       "      <td>2.320010e-07</td>\n",
       "      <td>3.096738e-08</td>\n",
       "      <td>-5.901894e-08</td>\n",
       "      <td>-0.000226</td>\n",
       "      <td>2.947356e-07</td>\n",
       "      <td>7.988754e-07</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.881615e-09</td>\n",
       "      <td>-2.757795e-07</td>\n",
       "      <td>-1.055870e-07</td>\n",
       "      <td>8.655298e-07</td>\n",
       "      <td>-0.000035</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0             1             2             3         4   \\\n",
       "0  1.080428e-08  3.430188e-07  6.303506e-08 -1.156729e-07 -0.000554   \n",
       "1 -3.050641e-08 -4.155728e-07 -7.710697e-08  1.441497e-07  0.000355   \n",
       "2  7.193171e-09  2.320010e-07  3.096738e-08 -5.901894e-08 -0.000226   \n",
       "\n",
       "             5             6         7         8             9             10  \\\n",
       "0  3.295821e-07  2.406693e-07  0.000007  0.000002  1.520470e-08 -1.238690e-06   \n",
       "1 -4.825485e-07 -1.067780e-06 -0.000017 -0.000003  1.164875e-08  7.607464e-07   \n",
       "2  2.947356e-07  7.988754e-07  0.000012  0.000001  1.881615e-09 -2.757795e-07   \n",
       "\n",
       "             11            12        13        14        15        16  \n",
       "0 -4.781419e-08  2.435864e-06 -0.000119 -0.000057  0.000088  0.000006  \n",
       "1 -4.410861e-08 -1.781377e-06  0.000075  0.000002 -0.000136 -0.000005  \n",
       "2 -1.055870e-07  8.655298e-07 -0.000035  0.000015  0.000120  0.000007  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#build baseline model:LogisticRegression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)\n",
    "y_val_pred1 = classifier.predict_proba(X_val)\n",
    "#calculate the coefficient of all the features\n",
    "classifier.coef_\n",
    "m=pd.DataFrame(classifier.coef_)\n",
    "print(\"These are all the coefficient of all features\")\n",
    "m.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculate the log_loss value for all the inputting features:\n",
      "test log_loss value for all the inputting features: 0.73989938182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suyun\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py:352: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train log_loss value for all the inputting features: 0.741926065087\n",
      "accuracy Scores for all the inputting features: [ 0.69476244  0.6957755   0.69668727  0.69466113  0.69466964] Accuracy: 0.70 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "#calculate the log_loss value for all the inputting features\n",
    "print(\"Calculate the log_loss value for all the inputting features:\")\n",
    "print(\"test log_loss value for all the inputting features:\",log_loss(y_val, y_val_pred1))\n",
    "y_train_pred1 = classifier.predict_proba(X_train)\n",
    "print(\"train log_loss value for all the inputting features:\",log_loss(y_train, y_train_pred1))\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(classifier, X, y, cv=5) \n",
    "print(\"accuracy Scores for all the inputting features:\", scores, \"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment1: choose 4,7,8,13,14,15,16 as independent vairables\n",
      "test log_loss value for 7 inputting features: 0.735695888506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suyun\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py:352: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train log_loss value for 7 inputting features: 0.73622832811\n",
      "accuracy Scores for 7 inputting features: [ 0.6912167   0.69547158  0.69557289  0.69314153  0.69365626] Accuracy: 0.69 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "#Experiment1:\n",
    "#choose 4,7,8,13,14,15,16 as independent variables\n",
    "print(\"Experiment1: choose 4,7,8,13,14,15,16 as independent vairables\")\n",
    "X_ef=X.iloc[:,[4,7,8,13,14,15,16]]\n",
    "classifier_xef = LogisticRegression()\n",
    "classifier_xef.fit(X_train.iloc[:,[4,7,8,13,14,15,16]], y_train)\n",
    "y_val_pred_xef = classifier_xef.predict_proba(X_val.iloc[:,[4,7,8,13,14,15,16]])\n",
    "print(\"test log_loss value for 7 inputting features:\",log_loss(y_val,y_val_pred_xef))\n",
    "y_train_pred_xef_t = classifier_xef.predict_proba(X_train.iloc[:,[4,7,8,13,14,15,16]])\n",
    "print(\"train log_loss value for 7 inputting features:\",log_loss(y_train, y_train_pred_xef_t))\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores_xef = cross_val_score(classifier_xef, X.iloc[:,[4,7,8,13,14,15,16]], y, cv=5) \n",
    "print(\"accuracy Scores for 7 inputting features:\", scores_xef, \"Accuracy: %0.2f (+/- %0.2f)\" % (scores_xef.mean(), scores_xef.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment2: choose 1,4,5,6,7,8,10,12,13,14,15,16 as independent vairables\n",
      "test log_loss value for 12 inputting features: 0.698265356954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suyun\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py:352: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train log_loss value for 12 inputting features: 0.699332138113\n",
      "accuracy Scores for 12 inputting features: [ 0.6912167   0.69628204  0.69638335  0.69496505  0.69669639] Accuracy: 0.70 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "#Experiment2:\n",
    "#choose 1,4,5,6,7,8,10,12,13,14,15,16 as independent variables\n",
    "print(\"Experiment2: choose 1,4,5,6,7,8,10,12,13,14,15,16 as independent vairables\")\n",
    "X_ef2=X.iloc[:,[1,4,5,6,7,8,10,12,13,14,15,16]]\n",
    "classifier_xef2 = LogisticRegression()\n",
    "classifier_xef2.fit(X_train.iloc[:,[1,4,5,6,7,8,10,12,13,14,15,16]], y_train)\n",
    "y_val_pred_xef2 = classifier_xef2.predict_proba(X_val.iloc[:,[1,4,5,6,7,8,10,12,13,14,15,16]])\n",
    "print(\"test log_loss value for 12 inputting features:\",log_loss(y_val,y_val_pred_xef2))\n",
    "y_train_pred_xef_t2 = classifier_xef2.predict_proba(X_train.iloc[:,[1,4,5,6,7,8,10,12,13,14,15,16]])\n",
    "print(\"train log_loss value for 12 inputting features:\",log_loss(y_train, y_train_pred_xef_t2))\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores_xef2 = cross_val_score(classifier_xef2, X.iloc[:,[1,4,5,6,7,8,10,12,13,14,15,16]], y, cv=5) \n",
    "print(\"accuracy Scores for 12 inputting features:\", scores_xef2, \"Accuracy: %0.2f (+/- %0.2f)\" % (scores_xef2.mean(), scores_xef2.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define 12 independent variables in the data to train the models\n",
    "X_train_12v=X_train.iloc[:,[1,4,5,6,7,8,10,12,13,14,15,16]]\n",
    "X_val_12v=X_val.iloc[:,[1,4,5,6,7,8,10,12,13,14,15,16]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train models:\n",
      "model1:GradientBosstingClassifier model\n",
      "test log_loss value: 0.598449255709\n",
      "train log_loss value: 0.483278612805\n",
      "accuracy Scores: [ 0.72687671  0.7371087   0.73508257  0.73650086  0.73338062] Accuracy: 0.73 (+/- 0.01)\n"
     ]
    }
   ],
   "source": [
    "#model1:GradientBosstingClassifier model\n",
    "print(\"Train models:\")\n",
    "print(\"model1:GradientBosstingClassifier model\")\n",
    "#train GradientBoostingClassifier model\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf = GradientBoostingClassifier(n_estimators=420,max_depth=4,subsample=0.7)\n",
    "clf.fit(X_train_12v, y_train)\n",
    "#use split test data to predict\n",
    "y_val_pred2 = clf.predict_proba(X_val_12v)\n",
    "#calculate the accuracy of test data by using log_loss\n",
    "print(\"test log_loss value:\",log_loss(y_val, y_val_pred2))\n",
    "y_train_pred2 = clf.predict_proba(X_train_12v)\n",
    "print(\"train log_loss value:\",log_loss(y_train, y_train_pred2))\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores1 = cross_val_score(clf, X.iloc[:,[1,4,5,6,7,8,10,12,13,14,15,16]], y, cv=5) \n",
    "print(\"accuracy Scores:\", scores1, \"Accuracy: %0.2f (+/- %0.2f)\" % (scores1.mean(), scores1.std() * 2))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model2: VotingClassifier model\n",
      "test log_loss value: 0.660839154259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suyun\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py:352: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train log_loss value: 0.416529647871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suyun\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py:352: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n",
      "C:\\Users\\suyun\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py:352: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n",
      "C:\\Users\\suyun\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py:352: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy Scores: [ 0.70793233  0.71461858  0.71320028  0.71249114  0.71402513] Accuracy: 0.71 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "#model2: VotingClassifier model\n",
    "#train VotingClassifier model\n",
    "print(\"model2: VotingClassifier model\")\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "clf1 = LogisticRegression(random_state=1)\n",
    "clf2 = RandomForestClassifier(random_state=1)\n",
    "clf3 = GaussianNB()\n",
    "eclf = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)], voting='soft',weights=[6,5,1])\n",
    "eclf.fit(X_train_12v, y_train)\n",
    "#use split test data to predict\n",
    "y_val_pred3 = eclf.predict_proba(X_val_12v)\n",
    "#calculate the accuracy of test data by using log_loss\n",
    "print(\"test log_loss value:\",log_loss(y_val, y_val_pred3))\n",
    "#calculate the accuracy of train data by using log_loss\n",
    "y_train_pred3 = eclf.predict_proba(X_train_12v)\n",
    "print(\"train log_loss value:\",log_loss(y_train, y_train_pred3))\n",
    "#calculate accuracy of train data by using cross_val_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores2 = cross_val_score(eclf, X.iloc[:,[1,4,5,6,7,8,10,12,13,14,15,16]], y, cv=5) \n",
    "print(\"accuracy Scores:\", scores2, \"Accuracy: %0.2f (+/- %0.2f)\" % (scores2.mean(), scores2.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model3: RandomForestClassifier model\n",
      "test log_loss value: 0.616012398071\n",
      "train log_loss value: 0.151888080693\n",
      "accuracy Scores: [ 0.72758586  0.72718063  0.73194205  0.72707932  0.72770572] Accuracy: 0.73 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "#model3: RandomForestClassifier model\n",
    "#train RandomForestClassifier model\n",
    "print(\"model3: RandomForestClassifier model\")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "clf_ran = RandomForestClassifier(n_estimators=1000)\n",
    "clf_ran.fit(X_train_12v, y_train)\n",
    "#use split test data to predict\n",
    "y_val_pred4=clf_ran.predict_proba(X_val_12v)\n",
    "#calculate the accuracy of test data by using log_loss\n",
    "print(\"test log_loss value:\",log_loss(y_val, y_val_pred4))\n",
    "#calculate the accuracy of train data by using log_loss\n",
    "y_train_pred4 = clf_ran.predict_proba(X_train_12v)\n",
    "print(\"train log_loss value:\",log_loss(y_train, y_train_pred4))\n",
    "#calculate accuracy of train data by using cross_val_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores3 = cross_val_score(clf_ran, X.iloc[:,[1,4,5,6,7,8,10,12,13,14,15,16]], y, cv=5) \n",
    "print(\"accuracy Scores:\", scores3, \"Accuracy: %0.2f (+/- %0.2f)\" % (scores3.mean(), scores3.std() * 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is test data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>building_id</th>\n",
       "      <th>created</th>\n",
       "      <th>description</th>\n",
       "      <th>display_address</th>\n",
       "      <th>features</th>\n",
       "      <th>latitude</th>\n",
       "      <th>listing_id</th>\n",
       "      <th>longitude</th>\n",
       "      <th>manager_id</th>\n",
       "      <th>photos</th>\n",
       "      <th>price</th>\n",
       "      <th>street_address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>79780be1514f645d7e6be99a3de696c5</td>\n",
       "      <td>2016-06-11 05:29:41</td>\n",
       "      <td>Large with awesome terrace--accessible via bed...</td>\n",
       "      <td>Suffolk Street</td>\n",
       "      <td>[Elevator, Laundry in Building, Laundry in Uni...</td>\n",
       "      <td>40.7185</td>\n",
       "      <td>7142618</td>\n",
       "      <td>-73.9865</td>\n",
       "      <td>b1b1852c416d78d7765d746cb1b8921f</td>\n",
       "      <td>[https://photos.renthop.com/2/7142618_1c45a2c8...</td>\n",
       "      <td>2950</td>\n",
       "      <td>99 Suffolk Street</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-06-24 06:36:34</td>\n",
       "      <td>Prime Soho - between Bleecker and Houston - Ne...</td>\n",
       "      <td>Thompson Street</td>\n",
       "      <td>[Pre-War, Dogs Allowed, Cats Allowed]</td>\n",
       "      <td>40.7278</td>\n",
       "      <td>7210040</td>\n",
       "      <td>-74.0000</td>\n",
       "      <td>d0b5648017832b2427eeb9956d966a14</td>\n",
       "      <td>[https://photos.renthop.com/2/7210040_d824cc71...</td>\n",
       "      <td>2850</td>\n",
       "      <td>176 Thompson Street</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3dbbb69fd52e0d25131aa1cd459c87eb</td>\n",
       "      <td>2016-06-03 04:29:40</td>\n",
       "      <td>New York chic has reached a new level ...</td>\n",
       "      <td>101 East 10th Street</td>\n",
       "      <td>[Doorman, Elevator, No Fee]</td>\n",
       "      <td>40.7306</td>\n",
       "      <td>7103890</td>\n",
       "      <td>-73.9890</td>\n",
       "      <td>9ca6f3baa475c37a3b3521a394d65467</td>\n",
       "      <td>[https://photos.renthop.com/2/7103890_85b33077...</td>\n",
       "      <td>3758</td>\n",
       "      <td>101 East 10th Street</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>783d21d013a7e655bddc4ed0d461cc5e</td>\n",
       "      <td>2016-06-11 06:17:35</td>\n",
       "      <td>Step into this fantastic new Construction in t...</td>\n",
       "      <td>South Third Street\\r</td>\n",
       "      <td>[Roof Deck, Balcony, Elevator, Laundry in Buil...</td>\n",
       "      <td>40.7109</td>\n",
       "      <td>7143442</td>\n",
       "      <td>-73.9571</td>\n",
       "      <td>0b9d5db96db8472d7aeb67c67338c4d2</td>\n",
       "      <td>[https://photos.renthop.com/2/7143442_0879e9e0...</td>\n",
       "      <td>3300</td>\n",
       "      <td>251  South Third Street\\r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100000</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>6134e7c4dd1a98d9aee36623c9872b49</td>\n",
       "      <td>2016-04-12 05:24:17</td>\n",
       "      <td>~Take a stroll in Central Park, enjoy the ente...</td>\n",
       "      <td>Midtown West, 8th Ave</td>\n",
       "      <td>[Common Outdoor Space, Cats Allowed, Dogs Allo...</td>\n",
       "      <td>40.7650</td>\n",
       "      <td>6860601</td>\n",
       "      <td>-73.9845</td>\n",
       "      <td>b5eda0eb31b042ce2124fd9e9fcfce2f</td>\n",
       "      <td>[https://photos.renthop.com/2/6860601_c96164d8...</td>\n",
       "      <td>4900</td>\n",
       "      <td>260 West 54th Street</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        bathrooms  bedrooms                       building_id  \\\n",
       "0             1.0         1  79780be1514f645d7e6be99a3de696c5   \n",
       "1             1.0         2                                 0   \n",
       "100           1.0         1  3dbbb69fd52e0d25131aa1cd459c87eb   \n",
       "1000          1.0         2  783d21d013a7e655bddc4ed0d461cc5e   \n",
       "100000        2.0         2  6134e7c4dd1a98d9aee36623c9872b49   \n",
       "\n",
       "                    created  \\\n",
       "0       2016-06-11 05:29:41   \n",
       "1       2016-06-24 06:36:34   \n",
       "100     2016-06-03 04:29:40   \n",
       "1000    2016-06-11 06:17:35   \n",
       "100000  2016-04-12 05:24:17   \n",
       "\n",
       "                                              description  \\\n",
       "0       Large with awesome terrace--accessible via bed...   \n",
       "1       Prime Soho - between Bleecker and Houston - Ne...   \n",
       "100             New York chic has reached a new level ...   \n",
       "1000    Step into this fantastic new Construction in t...   \n",
       "100000  ~Take a stroll in Central Park, enjoy the ente...   \n",
       "\n",
       "              display_address  \\\n",
       "0              Suffolk Street   \n",
       "1             Thompson Street   \n",
       "100      101 East 10th Street   \n",
       "1000     South Third Street\\r   \n",
       "100000  Midtown West, 8th Ave   \n",
       "\n",
       "                                                 features  latitude  \\\n",
       "0       [Elevator, Laundry in Building, Laundry in Uni...   40.7185   \n",
       "1                   [Pre-War, Dogs Allowed, Cats Allowed]   40.7278   \n",
       "100                           [Doorman, Elevator, No Fee]   40.7306   \n",
       "1000    [Roof Deck, Balcony, Elevator, Laundry in Buil...   40.7109   \n",
       "100000  [Common Outdoor Space, Cats Allowed, Dogs Allo...   40.7650   \n",
       "\n",
       "        listing_id  longitude                        manager_id  \\\n",
       "0          7142618   -73.9865  b1b1852c416d78d7765d746cb1b8921f   \n",
       "1          7210040   -74.0000  d0b5648017832b2427eeb9956d966a14   \n",
       "100        7103890   -73.9890  9ca6f3baa475c37a3b3521a394d65467   \n",
       "1000       7143442   -73.9571  0b9d5db96db8472d7aeb67c67338c4d2   \n",
       "100000     6860601   -73.9845  b5eda0eb31b042ce2124fd9e9fcfce2f   \n",
       "\n",
       "                                                   photos  price  \\\n",
       "0       [https://photos.renthop.com/2/7142618_1c45a2c8...   2950   \n",
       "1       [https://photos.renthop.com/2/7210040_d824cc71...   2850   \n",
       "100     [https://photos.renthop.com/2/7103890_85b33077...   3758   \n",
       "1000    [https://photos.renthop.com/2/7143442_0879e9e0...   3300   \n",
       "100000  [https://photos.renthop.com/2/6860601_c96164d8...   4900   \n",
       "\n",
       "                   street_address  \n",
       "0               99 Suffolk Street  \n",
       "1             176 Thompson Street  \n",
       "100          101 East 10th Street  \n",
       "1000    251  South Third Street\\r  \n",
       "100000       260 West 54th Street  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#upload test data\n",
    "test_df = pd.read_json(\"./input/test.json\")\n",
    "print(\"This is test data\")\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No null values in test data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "bathrooms          0\n",
       "bedrooms           0\n",
       "building_id        0\n",
       "created            0\n",
       "description        0\n",
       "display_address    0\n",
       "features           0\n",
       "latitude           0\n",
       "listing_id         0\n",
       "longitude          0\n",
       "manager_id         0\n",
       "photos             0\n",
       "price              0\n",
       "street_address     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to see if there's null value in the test data\n",
    "print(\"No null values in test data\")\n",
    "test_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#clean test data\n",
    "test_df[\"price_t\"] = test_df[\"price\"]/test_df[\"bedrooms\"] \n",
    "test_df[\"room_sum\"] = test_df[\"bedrooms\"]+test_df[\"bathrooms\"] \n",
    "test_df[\"num_photos\"] = test_df[\"photos\"].apply(len)\n",
    "test_df[\"num_features\"] = test_df[\"features\"].apply(len)\n",
    "test_df[\"num_description_words\"] = test_df[\"description\"].apply(lambda x: len(x.split(\" \")))\n",
    "test_df[\"created\"] = pd.to_datetime(test_df[\"created\"])\n",
    "test_df[\"created_year\"] = test_df[\"created\"].dt.year\n",
    "test_df[\"created_month\"] = test_df[\"created\"].dt.month\n",
    "test_df[\"created_day\"] = test_df[\"created\"].dt.day\n",
    "test_df[\"created_hour\"] = test_df[\"created\"].dt.hour\n",
    "#only choose the 12 independent variables:\n",
    "f1=[\"bedrooms\", \"price\",\"num_photos\", \"num_features\", \"num_description_words\",\n",
    "                        \"created_year\", \"created_day\", \"created_hour\"]\n",
    "#deal with address data and id data in the test dataset\n",
    "categorical = [\"display_address\", \"manager_id\", \"building_id\", \"street_address\"]\n",
    "for f in categorical:\n",
    "        if test_df[f].dtype=='object':\n",
    "            #print(f)\n",
    "            lbl = preprocessing.LabelEncoder()\n",
    "            lbl.fit( list(test_df[f].values))\n",
    "            test_df[f] = lbl.transform(list(test_df[f].values))\n",
    "            f1.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suyun\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py:352: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(74659, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use real test data to do LogisticRegression model prediction\n",
    "X_logisticr = test_df[f1]\n",
    "y_logisticr = classifier_xef2.predict_proba(X_logisticr)\n",
    "y_logisticr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'high': 0, 'low': 1, 'medium': 2}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#enumerate all the interest level\n",
    "labels2idx = {label: i for i, label in enumerate(classifier.classes_)}\n",
    "labels2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#write the predicted result in a csv file\n",
    "sub_logisticr = pd.DataFrame(y_logisticr)\n",
    "sub_logisticr[\"listing_id\"] = test_df.listing_id.values\n",
    "for label in [\"high\", \"medium\", \"low\"]:\n",
    "    sub_logisticr[label] = y_logisticr[:, labels2idx[label]]\n",
    "sub_logisticr.iloc[:,3:7].to_csv(\"submission_logisticr.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74659, 3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use real test data to do GradientBoostingClassifier model prediction\n",
    "X_GBC = test_df[f1]\n",
    "y_GBC = clf.predict_proba(X_GBC)\n",
    "y_GBC.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'high': 0, 'low': 1, 'medium': 2}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#enumerate all the interest level\n",
    "labels3idx = {label: i for i, label in enumerate(clf.classes_)}\n",
    "labels3idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#write the predicted result in a csv file\n",
    "sub_GBC = pd.DataFrame(y_GBC)\n",
    "sub_GBC[\"listing_id\"] = test_df.listing_id.values\n",
    "for label in [\"high\", \"medium\", \"low\"]:\n",
    "    sub_GBC[label] = y_GBC[:, labels3idx[label]]\n",
    "sub_GBC.iloc[:,3:7].to_csv(\"submission_GBC.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suyun\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py:352: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(74659, 3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use real test data to do VotingClassifier model prediction\n",
    "X_VC = test_df[f1]\n",
    "y_VC = eclf.predict_proba(X_VC)\n",
    "y_VC.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'high': 0, 'low': 1, 'medium': 2}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#enumerate all the interest level\n",
    "labels4idx = {label: i for i, label in enumerate(eclf.classes_)}\n",
    "labels4idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#write the predicted result in a csv file\n",
    "sub_VC = pd.DataFrame(y_VC)\n",
    "sub_VC[\"listing_id\"] = test_df.listing_id.values\n",
    "for label in [\"high\", \"medium\", \"low\"]:\n",
    "    sub_VC[label] = y_VC[:, labels4idx[label]]\n",
    "sub_VC.iloc[:,3:7].to_csv(\"submission_VC.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74659, 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use real test data to do VotingClassifier model prediction\n",
    "X_RAN = test_df[f1]\n",
    "y_RAN = clf_ran.predict_proba(X_RAN)\n",
    "y_RAN.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'high': 0, 'low': 1, 'medium': 2}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#enumerate all the interest level\n",
    "labels5idx = {label: i for i, label in enumerate(clf_ran.classes_)}\n",
    "labels5idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#write the predicted result in a csv file\n",
    "sub_RAN = pd.DataFrame(y_RAN)\n",
    "sub_RAN[\"listing_id\"] = test_df.listing_id.values\n",
    "for label in [\"high\", \"medium\", \"low\"]:\n",
    "    sub_RAN[label] = y_RAN[:, labels5idx[label]]\n",
    "sub_RAN.iloc[:,3:7].to_csv(\"submission_RAN.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
